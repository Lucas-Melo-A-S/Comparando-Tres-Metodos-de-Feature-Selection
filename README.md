
# Feature Selection em ClassificaÃ§Ã£o BinÃ¡ria  
## CorrelaÃ§Ã£o vs Boruta vs Feature Importance

Este repositÃ³rio apresenta uma anÃ¡lise comparativa entre **trÃªs mÃ©todos clÃ¡ssicos de Feature Selection** aplicados a um problema real de **classificaÃ§Ã£o binÃ¡ria de defeitos em software**, utilizando dados pÃºblicos do Kaggle.

O objetivo principal Ã© avaliar **como diferentes estratÃ©gias de seleÃ§Ã£o de variÃ¡veis impactam o desempenho, a estabilidade e a interpretabilidade dos modelos preditivos**.

---

## ğŸ“Œ Dataset

- **Fonte:** Kaggle â€” *Binary Classification with a Software Defects Dataset*
- **Linhas:** 71.234  
- **VariÃ¡veis:** 23  
- **Tipo:** Todas numÃ©ricas  
- **Valores nulos:** Nenhum  

Como as variÃ¡veis apresentam **escalas muito diferentes**, foi aplicada a padronizaÃ§Ã£o via **StandardScaler**, evitando que atributos com valores elevados dominassem o processo de modelagem.

---

## ğŸ§  Por que Feature Selection importa?

A seleÃ§Ã£o de variÃ¡veis Ã© uma etapa crÃ­tica em projetos de Machine Learning, pois:

- Reduz ruÃ­do
- Diminui overfitting
- Melhora o desempenho dos modelos
- Torna os resultados mais interpretÃ¡veis
- Reduz custo computacional

Neste projeto, avaliamos **nÃ£o apenas a lÃ³gica interna de cada mÃ©todo**, mas principalmente **seu impacto real nos modelos preditivos**.

---

## ğŸ”¬ MÃ©todos Avaliados

### 1ï¸âƒ£ CorrelaÃ§Ã£o (Filter Method)
- Remove apenas variÃ¡veis **altamente correlacionadas entre si** (threshold > 85%)
- Objetivo: evitar redundÃ¢ncia mantendo o mÃ¡ximo de informaÃ§Ã£o possÃ­vel

**VariÃ¡veis selecionadas:**

[â€˜locâ€™, â€˜idâ€™, â€˜Iâ€™, â€˜eâ€™, â€˜dâ€™, â€˜nâ€™, â€˜uniq_Opâ€™, â€˜v(g)â€™,
â€˜IOBlankâ€™, â€˜iv(g)â€™, â€˜ev(g)â€™, â€˜IOCommentâ€™, â€˜IoCodeAndCommentâ€™]

---

### 2ï¸âƒ£ Boruta (Wrapper Method)
- MÃ©todo extremamente rigoroso
- Compara a importÃ¢ncia real das variÃ¡veis com versÃµes aleatÃ³rias ("shadow features")
- MantÃ©m apenas variÃ¡veis consistentemente relevantes

**VariÃ¡veis selecionadas:**

[â€˜locâ€™, â€˜tâ€™, â€˜vâ€™]

---

### 3ï¸âƒ£ Feature Importance (Embedded Method â€“ Random Forest)
- Baseado na reduÃ§Ã£o de impureza dos splits em modelos de Ã¡rvore
- Aplicado cutoff de **30% de importÃ¢ncia mÃ­nima**

**VariÃ¡veis selecionadas:**

[â€˜locâ€™, â€˜v(g)â€™, â€˜iv(g)â€™, â€˜nâ€™, â€˜vâ€™, â€˜dâ€™, â€˜iâ€™, â€˜eâ€™, â€˜tâ€™,
â€˜lOCodeâ€™, â€˜total_Opâ€™, â€˜total_Opndâ€™, â€˜branchCountâ€™]

---

## ğŸ¤– Modelos Avaliados

Os conjuntos de variÃ¡veis selecionados foram testados em diferentes modelos, com destaque para:

- **XGBoost**
- RegressÃ£o LogÃ­stica
- Random Forest

As mÃ©tricas analisadas incluem:
- ROC AUC
- Gini
- KS
- Precisionâ€“Recall
- Matrizes de confusÃ£o
- GrÃ¡ficos de ordenaÃ§Ã£o por score

---

## ğŸ“Š Principais Resultados

### ğŸ”¹ CorrelaÃ§Ã£o
- **Melhor desempenho geral**
- Maior AUC e Gini
- Curvas ROC e Precisionâ€“Recall mais estÃ¡veis
- Excelente separaÃ§Ã£o entre classes

â¡ï¸ Remover apenas redundÃ¢ncias preserva informaÃ§Ã£o relevante e favorece modelos complexos.

---

### ğŸ”¹ Feature Importance
- Excelente equilÃ­brio entre desempenho e simplicidade
- XGBoost apresentou alta estabilidade entre treino e teste
- Baixo indÃ­cio de overfitting

â¡ï¸ Ã“tima escolha quando se busca robustez sem agressividade excessiva.

---

### ğŸ”¹ Boruta
- Maior interpretabilidade
- Pequena queda de performance em modelos complexos
- Melhora desempenho de modelos lineares

â¡ï¸ Ideal quando explicabilidade Ã© mais importante que performance mÃ¡xima.

---

## ğŸ§  ConclusÃ£o

NÃ£o existe um mÃ©todo universalmente melhor â€” **a escolha depende do objetivo do projeto**:

| Objetivo | Melhor MÃ©todo |
|--------|---------------|
| MÃ¡ximo desempenho | CorrelaÃ§Ã£o |
| EquilÃ­brio desempenho Ã— simplicidade | Feature Importance |
| Interpretabilidade | Boruta |

> **LiÃ§Ã£o principal:**  
> MÃ©todos simples, quando bem aplicados, podem superar abordagens mais complexas.

---

## ğŸ“ Estrutura do RepositÃ³rio

    â”œâ”€â”€ notebooks/
    â”‚   â”œâ”€â”€ DeteccÌ§aÌƒo_de_Problemas_em_Softwares_CorrelacÌ§aÌƒo.ipynb
    â”‚   â”œâ”€â”€ DeteccÌ§aÌƒo_de_Problemas_em_Softwares_Boruta.ipynb
    â”‚   â””â”€â”€ DeteccÌ§aÌƒo_de_Problemas_em_Softwares_Feature_Selection.ipynb
    â”‚
    â”œâ”€â”€ README.md
    
    ---

## ğŸ”— Notebooks

- ğŸ“˜ Feature Selection â€“ Random Forest  
- ğŸ“˜ Boruta  
- ğŸ“˜ CorrelaÃ§Ã£o  

*(Os notebooks contÃªm todo o pipeline de prÃ©-processamento, seleÃ§Ã£o de variÃ¡veis, modelagem e avaliaÃ§Ã£o.)*

---

## ğŸ™Œ ConsideraÃ§Ãµes Finais

Este projeto demonstra, na prÃ¡tica, como **decisÃµes de Feature Selection influenciam diretamente o desempenho e a confiabilidade dos modelos de Machine Learning**.

Se tiver dÃºvidas, sugestÃµes ou quiser discutir melhorias, fique Ã  vontade para abrir uma issue ou comentar.  
Obrigado pela leitura!


â¸»
